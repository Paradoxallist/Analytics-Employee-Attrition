import pandas as pd
import matplotlib.pyplot as plt
from preprocessor import Preprocessor
from models.random_forest import RandomForestModel
from models.logistic_regression import LogisticRegressionModel
from models.gradient_boosting import GradientBoostingModel
from config import MODEL_CONFIGS

# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
raw_data = pd.read_csv("WA_Fn-UseC_-HR-Employee-Attrition.csv")

# –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–µ—Ä—Å–∏–π
processor = Preprocessor(raw_data)
split_versions = processor.train_test_split_versions()

# –ú–æ–¥–µ–ª–∏
model_classes = {
    "RandomForest": RandomForestModel,
    "LogisticRegression": LogisticRegressionModel,
    "GradientBoosting": GradientBoostingModel
}

# –°–±–æ—Ä —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
results = []

for version_name, (X_train, X_test, y_train, y_test) in split_versions.items():
    for model_name, model_class in model_classes.items():
        base_params = MODEL_CONFIGS[model_name]["base"]

        if model_name == "RandomForest":
            model = model_class(**base_params)
            print(f"\nüîé –í–µ—Ä—Å–∏—è: {version_name} | –ú–æ–¥–µ–ª—å: {model_name} (base)")
            model.train(X_train, y_train)
            _, _, roc_auc = model.evaluate(X_test, y_test)
            results.append({"Version": version_name, "Model": f"{model_name}_base", "ROC AUC": roc_auc})

            grid_params = MODEL_CONFIGS[model_name]["grid"]
            from itertools import product
            sample_grid = list(product(
                grid_params["n_estimators"][::50],
                grid_params["max_depth"][::5],
                grid_params["min_samples_split"][::25],
                grid_params["min_samples_leaf"][::10]
            ))[:3]

            for idx, (n_est, depth, min_split, min_leaf) in enumerate(sample_grid):
                custom_params = {
                    "n_estimators": n_est,
                    "max_depth": depth,
                    "min_samples_split": min_split,
                    "min_samples_leaf": min_leaf,
                    "random_state": 42,
                    "class_weight": "balanced"
                }
                model = model_class(**custom_params)
                print(f"\nüîé –í–µ—Ä—Å–∏—è: {version_name} | –ú–æ–¥–µ–ª—å: {model_name}_tuned_{idx}")
                model.train(X_train, y_train)
                _, _, roc_auc = model.evaluate(X_test, y_test)
                label = f"{model_name}_tuned_{idx}"
                results.append({"Version": version_name, "Model": label, "ROC AUC": roc_auc})
        else:
            model = model_class(**base_params)
            print(f"\nüîé –í–µ—Ä—Å–∏—è: {version_name} | –ú–æ–¥–µ–ª—å: {model_name}")
            model.train(X_train, y_train)
            _, _, roc_auc = model.evaluate(X_test, y_test)
            results.append({"Version": version_name, "Model": model_name, "ROC AUC": roc_auc})

# –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ DataFrame
results_df = pd.DataFrame(results)

# –í—ã–≤–æ–¥ –≤ –∫–æ–Ω—Å–æ–ª—å –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
print("\n===== –ú–æ–¥–µ–ª–∏ –ø–æ —É–±—ã–≤–∞–Ω–∏—é ROC AUC =====")
sorted_display = results_df.sort_values(by="ROC AUC", ascending=False)
for idx, row in sorted_display.iterrows():
    print(f"{row['Version']} | {row['Model']}: {row['ROC AUC']:.4f}")

# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
plt.figure(figsize=(14, 9))
sorted_results = results_df.sort_values(by="ROC AUC", ascending=True)
labels = sorted_results["Version"] + " | " + sorted_results["Model"]
plt.barh(labels, sorted_results["ROC AUC"])
plt.xlabel("ROC AUC Score")
plt.title("–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –ø–æ –≤–µ—Ä—Å–∏—è–º –¥–∞–Ω–Ω—ã—Ö")
plt.tight_layout()
plt.show()

